# Slack Channel Dump
# Channel ID: C0910QFKTSN
# Generated: 2025-10-10T18:36:37.935354
# Total Messages: 55

[2025-06-11T14:05:04.331559] Juanje Ojeda: <@U02F2L89YTS> has joined the channel
[2025-06-11T14:05:45.394589] Avihai Efrat: <@U020YLADEKA> has joined the channel
[2025-06-11T14:05:45.554719] Kanitha Chim: <@U02DXVBD5CP> has joined the channel
[2025-06-11T14:05:45.678759] Sameera Kalgudi: <@U04LP69FP6X> has joined the channel
[2025-06-11T14:05:45.785609] Ozan Unsal: <@U04NNGY4QQ2> has joined the channel
[2025-06-11T14:05:45.895969] Eitan Raviv: <@U04MGT65NQJ> has joined the channel
[2025-06-11T14:06:06.438239] Kanitha Chim: ia lol?
[2025-06-11T14:06:33.298579] Juanje Ojeda: set the channel description: Place for sharing tips, tricks and resources related to AI and how to use it for improving our work in Auto Toolchain
[2025-06-11T14:06:53.073519] Juanje Ojeda: Ouch
[2025-06-11T14:07:05.643659] Juanje Ojeda: I put it in spanish :sweat_smile:  I'll change it
[2025-06-11T14:07:24.999719] Juanje Ojeda: has renamed the channel from "wg-team-auto-toolchain-ia" to "wg-team-auto-toolchain-ai"
[2025-06-11T17:04:38.331959] Eitan Raviv: Thanks for setting this up <@U02F2L89YTS>
[2025-06-13T11:15:18.549189] Kanitha Chim: <https://docling-project.github.io/docling/#features>
[2025-06-26T19:10:07.263649] Juanje Ojeda: From: Anthropic
Title: Mastering Claude Code in 30 minutes
Free and open source, Gemini CLI brings Gemini directly into developersâ€™ terminals â€” with unmatched access for individuals.
Title: Gemini CLI: your open-source AI agent
I don't know if you watched <https://www.youtube.com/watch?v=6eBSHbLKuN0&amp;t=6s|the video that Petr shared about Cloud Code> (which he used for his project), but it's very interesting. The problem is that you need a pro account for anthropic.
Very recently, Google released a similar tool (but open source): <https://github.com/google-gemini/gemini-cli|Gemini cli>
Here is the blog post talking about it: <https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/>
It's basically the same tool (same options and ui), but working with gemini instead of claude, Well, and it's free, no need for a paid account. But it doesn't work (yet) with our RH account, but it works with your personal one. Although, I'm not sure about if we can use it for internal stuff. They say that those tools don't share the local stuff, but I don't really see how they can read and modify your code without sending it to the remote LLM server...
Very interesting tools for coding, working with agents and MCPs.
[2025-06-26T19:14:49.043039] Juanje Ojeda: From: Developers Digest
Title: Gemini CLI in 6 Minutes: Google's Free and Open-Source Coding Assistant
Here is a short video explaining a bit what gemini-cli is, how it compare with its competitors (claude-code) and showing it working a bit:
<https://www.youtube.com/watch?v=T76NbeTdDFA>
[2025-06-27T09:34:12.062519] Ozan Unsal: GitLab CI pipelines
Title: Pipeline #1889153567 Â· Red Hat / Edge / ci-cd / Pipe X / pipelines-as-code Â· GitLab
I was playning with gemini-cli and created a small <https://github.com/ozanunsal/pipelinebot|project> for checking our product build pipeline status. Finds the failed jobs, if it is failed in testing-farm, it traces testing-farm logs for the error log. Then it finds the possible cause of error and suggests how to fix. Here is an example of a failed <https://gitlab.com/redhat/edge/ci-cd/pipe-x/pipelines-as-code/-/pipelines/1889153567|pipeline>;

```(venv) ounsal@ounsal-thinkpadp16vgen1:~/repo/playground/pipeline-bot$ pipelinebot --project 35939621 --pipeline 1889153567
INFO:pipelinebot.gitlab_api:Fetching jobs for pipeline 1889153567
INFO:pipelinebot.gitlab_api:Retrieved 20 jobs from pipeline 1889153567
INFO:pipelinebot.summarizer:Found 2 failed jobs to process
INFO:pipelinebot.summarizer:Processing job 1/2: smoke-tests-fusa-minimal: [x86_64]
INFO:pipelinebot.gitlab_api:Fetching log for job 10465690769
INFO:pipelinebot.gitlab_api:Retrieved log for job 10465690769 (5462 characters)
INFO:pipelinebot.summarizer:Processing Testing Farm job: smoke-tests-fusa-minimal: [x86_64]
INFO:pipelinebot.summarizer:Processing job 2/2: smoke-tests-fusa-minimal: [aarch64]
INFO:pipelinebot.gitlab_api:Fetching log for job 10465689664
INFO:pipelinebot.gitlab_api:Retrieved log for job 10465689664 (5463 characters)
INFO:pipelinebot.summarizer:Processing Testing Farm job: smoke-tests-fusa-minimal: [aarch64]
================================================================================
ðŸš€ PIPELINE FAILURE ANALYSIS REPORT
================================================================================
Job 1: smoke-tests-fusa-minimal: [x86_64]
Reason: The boot validation process failed because the configuration for the 'qm' container has an incorrect checksum. This indicates that the container's configuration has been modified and no longer matches the expected state.
Possible Fixes: 1.  If the configuration change to the 'qm' container was intentional, update the expected checksum in the boot check configuration to the new value: `d73b490587fe25586d8a83dfee22179b4fe7b17f32d7e85a6ca1c7d68526c972`.
2.  If the change was unintentional, revert the 'qm' container's configuration to its original state so that it matches the expected checksum (`28ea142bf3a1720172251131e30f463305515a26ac76009f64f6b9a71af333b6`).

Job 2: smoke-tests-fusa-minimal: [aarch64]
Reason: The `auto-boot-check.service` failed due to a configuration checksum mismatch for the 'qm' container. This indicates that the container's configuration has been modified and no longer matches the expected state.
Possible Fixes: 1.  If the changes to the 'qm' container are intentional, update the expected checksum in the boot check configuration file located at `/usr/lib/boot-check.d/qm.conf`.
2.  If the container configuration change was unintentional, revert the 'qm' container to its original state or rebuild the image to ensure its checksum matches the expected value.```
When I actually checked the cause of failure, I can say that gemini made a really good process.

I repeated it with a successful pipeline. To see whether I am having false-negative results and it also worked.
```(venv) ounsal@ounsal-thinkpadp16vgen1:~/repo/playground/pipeline-bot$ pipelinebot --project 35939621 --pipeline 1891039231
INFO:pipelinebot.gitlab_api:Fetching jobs for pipeline 1891039231
INFO:pipelinebot.gitlab_api:Retrieved 20 jobs from pipeline 1891039231
================================================================================
ðŸš€ PIPELINE FAILURE ANALYSIS REPORT
================================================================================
All jobs passed! ðŸŽ‰```
We can get benefit from this project for checking the status of our pipelines. I have an issue with gemini when I containerized this project. It gives an authentication timeout but I'll work on it. Besides that I was trying different pipelines for detecting different error but I guess we have some quota and gemini becomes exhausted :cry: .
[2025-07-01T12:48:29.256199] Ozan Unsal: We can request gemini API_KEY for red hat accounts now <https://docs.google.com/document/d/1N-1CgMtU-R5eHJ5BOyLIe4jEj0rmvdmCz4i8u5YfiIE/edit?tab=t.0#heading=h.ltpr634bumh3>
[2025-07-01T13:26:47.942069] Paul Caramuto: <@U04N9LTR47M> has joined the channel
[2025-07-01T14:17:11.808609] Juanje Ojeda: Here is the konflux user support chatbot project:
<https://gitlab.cee.redhat.com/sp-ai/user-support-bot>
Very interesting.
[2025-07-01T14:26:28.024829] Juanje Ojeda: It's basically an app in Python that take documentation into an embedding database and run a LLM with a RAG (to access to the doc at that database). They probably deploy it in OpenShift and they'll connect the bot account in slack with that service. So, the chatbot can answer questions using the ingested docs.
The code looks good, and it's simple but all that you need for that. nice project for learning, but also for creating our own (or just use it, there nothing specific to konflux there).
[2025-07-02T16:43:58.348029] Paul Caramuto: I've been asking/investigating how to dump data from slack channels to NotebookLM, and the most difficult and lengthy process is getting the auth token approved to run the API
[2025-07-02T16:47:35.944909] Paul Caramuto: we can use the native slack API "retrieving" function, but we still have to get a PIA approval which can take a long time
[2025-07-02T16:48:55.085359] Paul Caramuto: Justin Pierce already went through that process and got it approved, you can find more info <https://source.redhat.com/groups/public/openshift/openshift_blog/building_a_custom_ai_advisor_from_slack_history|here> (the catch, you need to ask him to run it)
[2025-07-08T00:17:31.453799] Juanje Ojeda: Get started with the Model Context Protocol (MCP)
Title: Introduction - Model Context Protocol
Your open source AI agent, automating engineering tasks seamlessly.
Title: codename goose | codename goose
Enable multi-modal functionality by pairing LLMs to complete your tasks
Title: Lead/Worker Multi-Model Setup | codename goose
Hi. I've been playing around with local AI agents and <https://modelcontextprotocol.io/introduction|MCP servers> lately and I found this one: <https://block.github.io/goose/>
It's open source and it can work with many LLMs, including local ones. It's similar to Gemini-cli or Claude-code, but it's not tied to just one LLM, and it has other interesting characteristics, like sessions, projects, and more. It looks very easy to extend and it has this interesting feature for using different models in turns in the same session:
<https://block.github.io/goose/docs/tutorials/lead-worker>

I have't used it much yet. Just tried a bit. The UI is not so nice as claude-code or gemni-cli, but it has potential. We'll see.
[2025-07-08T00:28:43.860509] Juanje Ojeda: The AI coding agent built for the terminal.
Title: opencode
Another open source AI agent I came across recently is <https://opencode.ai/>
I heard good things, but i haven't tried it yet. It can run multiple agents in parallel in the same session, which looks useful (or messy :thinking_face: ) and suppose to be very fast.
[2025-07-09T13:13:17.421779] Avihai Efrat: Hi there :redhat_cowboy:
Coming out of short Q3 innovation days at the ISR office about AI and MCP and wanted to shre:
1. AI/Agents/MCP <https://docs.google.com/presentation/d/1VRO2xxv3BPra4ixy7kDm5p4FVGYoqqfTns6GJ6mP30Y/edit?slide=id.g36b7eb1a849_0_3295#slide=id.g36b7eb1a849_0_3295|intresting slides.>
2. Very interesting <https://github.com/redhat-ai-tools|MCP registry >with all kinds of goodies(as Slack MCP, Jira MCP etc ...) that would make your work easier by leveraging on them or adding your own MCP project there.
[2025-07-09T15:28:16.329459] Avihai Efrat: Finnaly got a successful connection with Jira with the following JIRA MCP config at Cursor!
Check out the cool results in the pic :star-struck:

```"jira": {
      "type": "stdio",
      "command": "podman",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "JIRA_URL",
        "-e",
        "JIRA_PERSONAL_TOKEN",
        "<http://ghcr.io/sooperset/mcp-atlassian:latest|ghcr.io/sooperset/mcp-atlassian:latest>"
      ],
      "env": {
        "JIRA_PERSONAL_TOKEN": "&lt;your token&gt;",
        "JIRA_URL": "<https://issues.redhat.com>"
      }
    ```
[2025-07-09T15:56:50.757039] Juanje Ojeda: Nice :heart_eyes:
[2025-07-19T02:23:09.550949] Inho Cho: <@U04AGK8UJ2V> has joined the channel
[2025-07-21T18:13:37.452919] Avihai Efrat: <!channel> - anyone think they have an associate who had a great example of AI usage in Q2?  Mike it looking for a lit of highlights for recognition?
From: Shawn Davis
Sender: Slack Conversation
Hi <!here>,
Posting this here if you have a Q2 great example of AI usage in a form of Demo or blog.
Please post it here and Iâ€™ll forward it to Shawn D. For some broad core platform level recognitions :trophy: 
[2025-07-24T13:39:22.914219] Kanitha Chim: Hey all, if you could share in this sheet the tool you have used that would be nice
<https://docs.google.com/spreadsheets/d/1Vdrb50eSiNLwM83qG8dj8eVwanLDB1CFbwZ3BveOa8g/edit?gid=0#gid=0>
[2025-07-28T04:10:29.426219] Kartik Shah: <@U03PXHBRX5Z> has joined the channel
[2025-08-11T16:29:12.447629] Avihai Efrat: :mega:. Are you interested in writing an MCP server?  or hooking up your AI agent to an MCP server?  Come and join us at today's 10am Data and AI Open Forum to learn about Red Hat's approved MCP template and innersource place to share your MCP server!
From: Tiffany Jacob
Sender: Thread in Slack Conversation
Hi hi folks! :face_with_cowboy_hat:
Sharing very cool slides about writing MCp servers easily slides and recording made last week 
[2025-08-11T19:20:57.401509] Lei Wang: <@URRPFQEMS> has joined the channel
[2025-08-11T19:29:35.696729] Nisha Saini: <@U04AGQD0K8D> has joined the channel
[2025-08-18T15:16:42.677819] Juanje Ojeda: Share your videos with friends, family, and the world
Title: IA concepts
In case anyone is interested on understanding a bit better some of the basic concepts about generative AI, how LLMs work, RAG, agents and other AI related topics, I curated a YouTuve list with good quality (and short) explanations. FYI, the videos have a logical and incremental order, so I recommend to follow it, but you can do as you wish :sweat_smile:
<https://youtube.com/playlist?list=PLfZui7DiPOPgU34wnruAMXcR_EzsnFSiB&amp;si=KYPwcBurIuDoXVID>
[2025-08-19T11:51:12.876729] Juanje Ojeda: *Agile AI Assistant - Next Phase*

Back in June, we launched the initial version of the *Agile AI Assistant*. Our goal was to integrate internal Red Hat agile practices and make them accessible through a combination of the AI Combinator and Shadowbot. However, due to team reorganizations and reprioritizations, we've pivoted to using *NotebookLM* for the MVP instead.
Our first results, based on a small selection of sources, were promising but not overwhelming. Now, we're expanding the knowledge base for the next phase. We've added all articles from the *Agile and Tooling Knowledge Hub*, the *2020 Scrum Guide*, and the *Open Decision Framework*.

You can access the Agile AI Assistant here: <https://red.ht/45ErTEN>

Please give it a try and share your thoughts! What's working well? What's missing? What could be improved? Your feedback is crucial as we move forward.

*Agile AI Assistant Confluence space:* <https://spaces.redhat.com/spaces/AAA/pages/614009143/Agile+AI+Assistant>
*Slack conversations:* <#C0845CDHS1X|>
From: Jimmy Sjolund
Sender: Thread in Slack Conversation
Interesting :thinking_face:
[2025-08-19T12:40:02.256339] Kanitha Chim: I added a small project [1] to use Gemini to review gitlab MR. Just sharing here in case anyone wants to enable it in your repo.
[1] <https://gitlab.cee.redhat.com/automotive/toolshed/automate-code-review>
[2025-08-25T11:57:52.969279] Michael Ho: <@U04JRTQ4LHK> has joined the channel
[2025-09-01T12:58:11.051129] Michael Ho: From: Yifan - Beyond the Hype
Title: I Reverse-Engineered Claude Code: Learn These Agent Tricks
I showed <@U02F2L89YTS> this <https://www.youtube.com/watch?v=i0P56Pm1Q3U|video> and he asked I bring it up here to share further :meow_smilesweat:  Didi shared this to us in a FoA meeting and it is very illuminating how Claude Code works and why simple llm prompting with local llms isn't equivalent
[2025-09-01T13:58:02.113409] Juanje Ojeda: Following the "behind the curtin" trend, here is a code example I did to understand how the "tool calling" (which later was used for the MCPs) actually works "under de hood":
<https://github.com/juanje/llm-tool-calling/blob/main/pseudo_tool_calling.py>

That's with a old model that doesn't support "tool calling", to see what exactly the LLM (and the ai app) does.
Then, they started to train models with thousands of examples for this, so now the models "understand" what to do when you pass a JSON schema for using a function or a tool.
So, now you can do it "natively" like this:
<https://github.com/juanje/llm-tool-calling/blob/main/real_tool_calling.py>
Here is the high level explanation and shorter version of the code:
<https://github.com/juanje/llm-tool-calling>
[2025-09-01T14:05:21.498729] Juanje Ojeda: *For learning*
Here you have a simple chatbot done with LangChain (a very good and standard lib for creating chatbots and agents) and Ollama (to work with local models).
There you can learn how to talk with the LLMs and do basic ai app stuff: <https://github.com/juanje/simple-chatbot>
And this is the same chartbot but with a simple (pssudo)RAG, so you can talk with a knowledge database. It's not using a tipical vector database, but a simple json file as a "database" for the retrieval part, to simplify things and focos on how the RAG actually works instead of focusing on the infra part or the extracting/embedding part.
<https://github.com/juanje/simple-chatbot-miniRAG>
[2025-09-02T00:57:05.515109] Luigi Pellecchia: <@U04Q4USRZTM> has joined the channel
[2025-09-02T06:12:58.401709] Luigi Pellecchia: Hi and thanks for adding me to this channel!
We are working on a Test Console ChatBot, early stages, and we are investigating a few things: <https://issues.redhat.com/browse/VROOM-32061>
The goal is to have a chat bot able to interact with Test Console data, retrieving information and creating requests in our system.
Due to that we have some questions such as:
â€¢ what is the best interface to share with the ai in terms of tools? direct db access, api, python module, ad hoc
â€¢ where to store the conversation history (in browser, db, not needed)
â€¢ we need RAG? (it is enough to describe the tools or we need additional context?)
â€¢ which LLM is better for our us case? (Gemini? we don't need to ask about the universe! An LLM deployed with Ollama?)
Any insight will be useful!
[2025-09-08T15:40:53.177869] Rakesh Musalay: <@U04N0SVB92Q> has joined the channel
[2025-09-08T23:24:41.403169] Juanje Ojeda: Generate context with up-to-date documentation for LLMs and AI code editors
Title: Context7 - Up-to-date documentation for LLMs and AI code editors
I recommend anyone that's using Cursor, claude-code or any other AI tool for coding to us <https://context7.com/>
The LLM often have old knowledge about the libraries, APIs, etc and they can make the wrong assumptions, put the wrong versions or use deprecated functions. Context7 is an MCP server that give to the IDE the tools for checking the latest documentation for most of the libs you'll ever use.
As a tip, add also to your cursor rules or your CLAUDE.md files to check with context7 before creating a new project, add a new library or while debugging errors. The results are normally much better.
[2025-09-09T06:41:36.846829] Maya Peretz: <@U02CVB7MDK8> has joined the channel
[2025-09-10T13:36:27.314159] Yosi Ben Shimon: <@U01552Z34RG> has joined the channel
[2025-09-10T13:36:56.319329] Avihai Efrat: <@U01552Z34RG> FYI for AI links are here ^â‚¬
[2025-09-13T18:07:22.447209] Juanje Ojeda: From: Tech With Tim
Title: How to Build a Local AI Agent With Python (Ollama, LangChain &amp; RAG)
Here you have a nice didactic video for building a super-simple chatbot in Python with langchain + ollama. And then adding a simple RAG using chroma for the vector database.
It's super simple, but enough to see how that actually works at a basic level:
<https://www.youtube.com/watch?v=E4l91XKQSgw>
[2025-09-13T18:10:14.784869] Juanje Ojeda: From: 3Blue1Brown
Title: Transformers, the tech behind LLMs | Deep Learning Chapter 5
And for ppl more advance or that like to understand what the LLMs and the transformers really are, this is a masterpiece that explains many machine learning concepts, what are transformers and LLM, and how they work. Super interesting, but maybe not for everyone :sweat_smile:
<https://www.youtube.com/watch?v=wjZofJX0v4M>
[2025-09-29T09:48:49.303799] Avihai Efrat: Happy Monday AI enthusiasts:zap:
Sharing a very cool vid (~1H) but totally worth it about Agentic AI I watch yesturday(also shared in mail "Red Hat 101: Agentic AI now available on demand") :
<https://source.redhat.com/about_red_hat/red_hat_101/red_hat_101/red_hat_101_agentic_ai>
[2025-10-07T17:31:35.881999] Juanje Ojeda: From: IBM Technology
Title: A2A Protocol (Agent2Agent) Explained: How AI Agents Collaborate
Interesting :thinking_face:
<https://www.youtube.com/watch?v=Tud9HLTk8hg>
[2025-10-07T17:32:00.981159] Juanje Ojeda: The Agent2Agent protocol is an open standard that allows different AI agents to securely communicate, collaborate, and solve complex problems together.
Title: A2A Protocol
&gt; The *Agent2Agent (A2A) Protocol* is an open standard developed by Google and donated to the Linux Foundation designed to enable seamless communication and collaboration between AI agents.
<https://a2a-protocol.org/latest/>
[2025-10-09T18:29:42.248519] Juanje Ojeda: Built to make you extraordinarily productive, Cursor is the best way to code with AI.
Title: Introducing Plan Mode Â· Cursor
If you're using Cursor for creating new projects or features for your projects, this new feature could be useful. I've just tried and it's looking good.
If you normally as Cursor to create a detailed plan before starting to work, this is similar, but it's more integrated. It ask you some questions to clarify the goal and constraints and the create a detailer plan and ToDo. It saves the plan in markdown for future reference or changing stuff. Then you hit "build" and it start building the project/feature.
<https://cursor.com/blog/plan-mode>
